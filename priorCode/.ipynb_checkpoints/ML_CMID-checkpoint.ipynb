{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "valqgLJKJDXK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OEe7GkTglctl",
    "outputId": "45f325a3-3e64-4180-8798-7c9f1fc77c7d"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/gdrive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PHoKUrZTXuAP",
    "outputId": "a09d0dfd-c599-4e29-8c1a-74ade111de45"
   },
   "outputs": [],
   "source": [
    "rmdir /content/gdrive/MyDrive/Colab Notebooks/CMID_Imbalanced/.ipynb_checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "86fCb5pj6qCF"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.keras.layers as tfl\n",
    "import scipy.misc\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "# from resnets_utils import *\n",
    "from tensorflow.keras.initializers import random_uniform, glorot_uniform, constant, identity\n",
    "from tensorflow.python.framework.ops import EagerTensor\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow.keras.layers as tfl\n",
    "\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomRotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hkNWX28IKn43",
    "outputId": "5b305388-4da6-45a1-ff84-20501db543e7"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "# IMG_SIZE = (160, 160) #for mobileNet v1\n",
    "IMG_SIZE = (224, 224) #for resnet50\n",
    "# directory = \"dataset/\"\n",
    "\n",
    "directory = \"/content/gdrive/MyDrive/Colab Notebooks/CMID/\"\n",
    "\n",
    "train_dataset = image_dataset_from_directory(directory,\n",
    "                                            #  labels='inferred',\n",
    "                                             label_mode='binary',\n",
    "                                             shuffle=True,\n",
    "                                             batch_size=BATCH_SIZE,\n",
    "                                             image_size=IMG_SIZE,\n",
    "                                             validation_split=0.2,\n",
    "                                             subset='training',\n",
    "                                            #  label_mode = tf.float32,\n",
    "                                             seed=42)\n",
    "validation_dataset = image_dataset_from_directory(directory,\n",
    "                                                  # labels='inferred',\n",
    "                                                  label_mode='binary',\n",
    "                                                  shuffle=True,\n",
    "                                                  batch_size=BATCH_SIZE,\n",
    "                                                  image_size=IMG_SIZE,\n",
    "                                                  validation_split=0.2,\n",
    "                                                  subset='validation',\n",
    "                                                  seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Efq1HQQHHQ2T",
    "outputId": "ac092450-6065-4961-cac4-640ae4a23e65"
   },
   "outputs": [],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SPSNzLX4KrjH"
   },
   "outputs": [],
   "source": [
    "class_names = train_dataset.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oRh1CsggXGM7"
   },
   "outputs": [],
   "source": [
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GRXuDYGAKtZW",
    "outputId": "191af3cd-66ad-4b8b-e80c-728391eaf16f"
   },
   "outputs": [],
   "source": [
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VXbTPSQr21k-",
    "outputId": "a8f3d540-1a17-46c3-d78a-3e4d374222fa"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for images, labels in train_dataset: # train_dataset.take(1):\n",
    "  # print(images.shape, labels.shape)\n",
    "  if(i==0):\n",
    "    X_train = images\n",
    "    y_train = labels\n",
    "  else:\n",
    "    X_train = tf.concat([X_train, images], 0)\n",
    "    y_train = tf.concat([y_train, labels], 0)\n",
    "\n",
    "  i = i + 1\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y_lEbxvCavdq",
    "outputId": "74065939-6dfa-4ce2-dd5c-bc80c84fcad5"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for images, labels in validation_dataset: # train_dataset.take(1):\n",
    "  # print(images.shape, labels.shape)\n",
    "  if(i==0):\n",
    "    X_valid = images\n",
    "    y_valid = labels\n",
    "  else:\n",
    "    X_valid = tf.concat([X_valid, images], 0)\n",
    "    y_valid = tf.concat([y_valid, labels], 0)\n",
    "\n",
    "  i = i + 1\n",
    "print(X_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "onX39IkCkvL8"
   },
   "outputs": [],
   "source": [
    "#SVM on CMID datasets\n",
    "#dataset preparation\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "flat_X_train = []\n",
    "flat_y_train = []\n",
    "for i in range(0, len(X_train)):\n",
    "  img_array = X_train[i]\n",
    "  img_resized = resize(img_array, [224, 224, 3])\n",
    "  flat_X_train.append(img_resized.flatten())\n",
    "\n",
    "for i in range(0, len(y_train)):\n",
    "  flat_y_train.append(int(y_train[i]))\n",
    "\n",
    "flat_X_train = np.array(flat_X_train)\n",
    "flat_y_train = np.array(flat_y_train)\n",
    "\n",
    "flat_X_valid = []\n",
    "flat_y_valid = []\n",
    "for i in range(0, len(X_valid)):\n",
    "  img_array = X_valid[i]\n",
    "  img_resized = resize(img_array, [224, 224, 3])\n",
    "  flat_X_valid.append(img_resized.flatten())\n",
    "\n",
    "for i in range(0, len(y_valid)):\n",
    "  flat_y_valid.append(int(y_valid[i]))\n",
    "\n",
    "flat_X_valid = np.array(flat_X_valid)\n",
    "flat_y_valid = np.array(flat_y_valid)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "flat_X_train = scaler.fit_transform(flat_X_train)\n",
    "flat_X_valid = scaler.fit_transform(flat_X_valid)\n",
    "#full dataset\n",
    "X_main = np.concatenate((flat_X_train, flat_X_valid), axis=0) #flat_X_train.append(flat_X_valid)\n",
    "y_main = np.concatenate((flat_y_train, flat_y_valid), axis=0) #flat_y_train.append()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hHjyHTFTOxoz",
    "outputId": "20f3ce8b-f927-4a23-f7e3-9317fec1cc8c"
   },
   "outputs": [],
   "source": [
    "X = X_main; y = y_main #train with ALL the datasets\n",
    "# X = X_main[0:400]; y = y_main[0:400] #train with FIRST half of the datasets\n",
    "# X = X_main[400:791]; y = y_main[400:791] #train with SECOND half of the datsets\n",
    "# test_X = X_main[0:100]; test_y = y_main[0:100] #test datasets\n",
    "print('X and y shape= ', X.shape, y.shape)\n",
    "# print('test_X and test_y shape= ', test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FSn86YFW1Jtd"
   },
   "outputs": [],
   "source": [
    "# ML model training\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# # param_grid={'C':[0.1,1,10,100],'gamma':[0.0001,0.001,0.1,1],'kernel':['rbf','poly']}\n",
    "# param_grid={'C':[1],'gamma':[0.0001],'kernel':['rbf']}\n",
    "\n",
    "from sklearn import svm\n",
    "svm_clf = svm.SVC(kernel='rbf', C=1, gamma=0.0001) # for cross validation\n",
    "# for normal classification\n",
    "# svc_prob=svm.SVC(probability=True)\n",
    "# for grid search \n",
    "# svm_clf=GridSearchCV(svc_prob,param_grid)\n",
    "\n",
    "# svm_clf.fit(X, y)\n",
    "# y_pred_test = svm_clf.predict(test_X)\n",
    "\n",
    "# from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "# print('test acc=', accuracy_score(test_y, y_pred_test))\n",
    "# print('precision=', np.mean(precision_score(test_y, y_pred_test, average=None)))\n",
    "# print('recall=   ', np.mean(recall_score(test_y, y_pred_test, average=None)))\n",
    "# print('f1=       ', np.mean(f1_score(test_y, y_pred_test, average=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "sgghiNt_RmTd",
    "outputId": "e221dfe8-0f95-4242-acbd-7b16374a01fd"
   },
   "outputs": [],
   "source": [
    "# # ML model training using Random Forest, XGBoost\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# # param_grid={'n_estimators':[16, 32, 64, 128],'max_leaf_nodes':[8, 16, 32]}\n",
    "# param_grid={'n_estimators':[32],'max_leaf_nodes':[16]}\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=32, max_leaf_nodes=16, n_jobs=-1)\n",
    "# for normal classification\n",
    "# rf_normal=RandomForestClassifier(n_jobs=-1)\n",
    "#for grid search \n",
    "# rf_clf=GridSearchCV(rf_normal,param_grid)\n",
    "\n",
    "rf_clf.fit(X, y)\n",
    "# y_pred_test = rf_clf.predict(test_X)\n",
    "\n",
    "# print('test acc=', accuracy_score(test_y, y_pred_test))\n",
    "# print('precision=', np.mean(precision_score(test_y, y_pred_test, average=None)))\n",
    "# print('recall=   ', np.mean(recall_score(test_y, y_pred_test, average=None)))\n",
    "# print('f1=       ', np.mean(f1_score(test_y, y_pred_test, average=None)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o6KjYJQ_14Wx",
    "outputId": "60ef3cd3-73af-4520-aaf1-f9abc3392030"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "y_pred_test = rf_clf.predict(X)\n",
    "\n",
    "print('test acc=', accuracy_score(y, y_pred_test))\n",
    "print('precision=', np.mean(precision_score(y, y_pred_test, average=None)))\n",
    "print('recall=   ', np.mean(recall_score(y, y_pred_test, average=None)))\n",
    "print('f1=       ', np.mean(f1_score(y, y_pred_test, average=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "eQkVegPQ2Y6E",
    "outputId": "f686f2ac-9f52-443b-b19a-b1749f831403"
   },
   "outputs": [],
   "source": [
    "def plot_digit(data):\n",
    "    image = data.reshape(224, 224, 3) #(28, 28)\n",
    "    plt.imshow(image, cmap = mpl.cm.hot,\n",
    "               interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "\n",
    "plot_digit(rf_clf.feature_importances_)\n",
    "\n",
    "cbar = plt.colorbar(ticks=[rf_clf.feature_importances_.min(), rf_clf.feature_importances_.max()])\n",
    "cbar.ax.set_yticklabels(['Not important', 'Very important'])\n",
    "\n",
    "# save_fig(\"mnist_feature_importance_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "3rF4b0-28g5y",
    "outputId": "93fae1cd-5fe4-409a-a066-55a203ee856d"
   },
   "outputs": [],
   "source": [
    "importances = rf_clf.feature_importances_\n",
    "importances = importances.reshape((384, -1))\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(importances)\n",
    "plt.title(\"Feature Importance Plot for Color Image (Random Forest)\")\n",
    "plt.axis('off')\n",
    "plt.colorbar(label='Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X3fsNbDT4um6",
    "outputId": "c47e8342-5d0b-4a75-e361-de169bfaa765"
   },
   "outputs": [],
   "source": [
    "# importances = rf_clf.feature_importances_\n",
    "importances[importances > 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FacleCRz30y3",
    "outputId": "1975823b-beb0-4bfe-a905-691b772a675a"
   },
   "outputs": [],
   "source": [
    "# rf_clf.feature_importances_.max()\n",
    "\n",
    "for name, score in zip(X[0], rf_clf.feature_importances_):\n",
    "    print(name, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DmFwwawhkzZ5",
    "outputId": "5f0468fa-62c7-4cbf-c08a-39db2fa2908c"
   },
   "outputs": [],
   "source": [
    "#cross validation\n",
    "\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score),\n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score),\n",
    "           'f1_score' : make_scorer(f1_score)}\n",
    "\n",
    "results1 = cross_validate(svm_clf, X, y, cv=5, scoring=scoring, n_jobs=-1)\n",
    "print('svm acc, std, precision, recall, f1_score=', np.mean(results1['test_accuracy']), np.std(results1['test_accuracy']), np.mean(results1['test_precision']), np.mean(results1['test_recall']), np.mean(results1['test_f1_score']))\n",
    "results = cross_validate(rf_clf, X, y, cv=5, scoring=scoring, n_jobs=-1)\n",
    "print('rf acc, std, precision, recall, f1_score=', np.mean(results['test_accuracy']), np.std(results['test_accuracy']), np.mean(results['test_precision']), np.mean(results['test_recall']), np.mean(results['test_f1_score']))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
