{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xordm9PcKn8H",
    "outputId": "d3df4f97-2cbf-48db-beb1-0518c00a2599"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/gdrive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xiWlnF-SMUOe"
   },
   "outputs": [],
   "source": [
    "# rmdir /content/gdrive/MyDrive/Colab Notebooks/CMID/.ipynb_checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2hi3UWRJKvUE"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "from tensorflow.python.framework.ops import EagerTensor\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "80_m94UKKzVM",
    "outputId": "6a665c33-092f-48b1-e759-796694147544"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "directory = \"/content/gdrive/MyDrive/Colab Notebooks/CMID/\"\n",
    "\n",
    "train_dataset = image_dataset_from_directory(directory,\n",
    "                                             shuffle=True,\n",
    "                                             batch_size=BATCH_SIZE,\n",
    "                                             image_size=IMG_SIZE,\n",
    "                                             validation_split=0.2,\n",
    "                                             subset='training',\n",
    "                                            #  label_mode = tf.float32,\n",
    "                                             seed=42)\n",
    "validation_dataset = image_dataset_from_directory(directory,\n",
    "                                             shuffle=True,\n",
    "                                             batch_size=BATCH_SIZE,\n",
    "                                             image_size=IMG_SIZE,\n",
    "                                             validation_split=0.2,\n",
    "                                             subset='validation',\n",
    "                                             seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mC4ueTAgK56j",
    "outputId": "b5d7ba70-0908-47e8-b117-c3916a73b56f"
   },
   "outputs": [],
   "source": [
    "class_names = train_dataset.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HZWNcUR5K-6D",
    "outputId": "3c90a69a-f07f-494b-9ad4-ec2a8d257822"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for images, labels in train_dataset: # train_dataset.take(1):\n",
    "  # print(images.shape, labels.shape)\n",
    "  if(i==0):\n",
    "    X_train = images\n",
    "    y_train = labels\n",
    "  else:\n",
    "    X_train = tf.concat([X_train, images], 0)\n",
    "    y_train = tf.concat([y_train, labels], 0)\n",
    "\n",
    "  i = i + 1\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "i = 0\n",
    "for images, labels in validation_dataset: # train_dataset.take(1):\n",
    "  # print(images.shape, labels.shape)\n",
    "  if(i==0):\n",
    "    X_valid = images\n",
    "    y_valid = labels\n",
    "  else:\n",
    "    X_valid = tf.concat([X_valid, images], 0)\n",
    "    y_valid = tf.concat([y_valid, labels], 0)\n",
    "\n",
    "  i = i + 1\n",
    "print(X_valid.shape, y_valid.shape)\n",
    "\n",
    "#CONCATENATING TRAINING AND VALIDATION IMAGES for GAN Model\n",
    "X = tf.concat([X_train, X_valid], 0)\n",
    "y = tf.concat([y_train, y_valid], 0)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P-RUsWKmLYbL",
    "outputId": "2a43039f-aa05-422d-da85-7ca1e4e42ace"
   },
   "outputs": [],
   "source": [
    "#X_train for training the GAN model\n",
    "flip = 0\n",
    "for i in range(len(y)):\n",
    "  if y[i] == 0: #0 for defective and 1 for non defective\n",
    "    if flip == 0:\n",
    "      X_train = [X[i]]\n",
    "      flip=1\n",
    "    else:\n",
    "      X_train = tf.concat([X_train, [X[i]]], 0)\n",
    "X_train = tf.concat([X_train, X_train, X_train], 0) # making it tripple\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oofki-m6LDX7",
    "outputId": "e734a4dc-92b7-46b1-a2cd-79427055495d"
   },
   "outputs": [],
   "source": [
    "#normalizing the dataset\n",
    "X_train = X_train / 255.0\n",
    "\n",
    "n_H, n_W, n_C = [224, 224, 3]\n",
    "n_classes =1\n",
    "print(n_H, n_W, n_C )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WxxS_hGpLQEK"
   },
   "outputs": [],
   "source": [
    "#use for AE, CAE, VAE\n",
    "def show_reconstructions(model, images=X_valid, n_images=10):\n",
    "    reconstructions = model.predict(images[:n_images])\n",
    "    fig = plt.figure(figsize=(n_images * 1.5, 3))\n",
    "    for image_index in range(n_images):\n",
    "        plt.subplot(2, n_images, 1 + image_index)\n",
    "        plot_image(images[image_index])\n",
    "        plt.subplot(2, n_images, 1 + n_images + image_index)\n",
    "        plot_image(reconstructions[image_index])\n",
    "\n",
    "def plot_multiple_images(images, n_cols=None):\n",
    "    n_cols = n_cols or len(images)\n",
    "    n_rows = (len(images) - 1) // n_cols + 1\n",
    "    if images.shape[-1] == 1:\n",
    "        images = np.squeeze(images, axis=-1)\n",
    "    plt.figure(figsize=(n_cols, n_rows))\n",
    "    for index, image in enumerate(images):\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(image, cmap=\"binary\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "def train_gan(gan, dataset, batch_size, codings_size, n_epochs=50):\n",
    "    generator, discriminator = gan.layers\n",
    "    gan_loss = 1000\n",
    "    for epoch in range(n_epochs):\n",
    "        loss = []\n",
    "        print(\"Epoch {}/{}\".format(epoch + 1, n_epochs))              # not shown in the book\n",
    "        for X_batch in dataset:\n",
    "            # phase 1 - training the discriminator\n",
    "            noise = tf.random.normal(shape=[batch_size, codings_size])\n",
    "            generated_images = generator(noise)\n",
    "            X_fake_and_real = tf.concat([generated_images, X_batch], axis=0)\n",
    "            y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n",
    "            discriminator.trainable = True\n",
    "            discriminator.train_on_batch(X_fake_and_real, y1)\n",
    "\n",
    "            # phase 2 - training the generator\n",
    "            noise = tf.random.normal(shape=[batch_size, codings_size])\n",
    "            y2 = tf.constant([[1.]] * batch_size)\n",
    "            discriminator.trainable = False\n",
    "            temp_loss = gan.train_on_batch(noise, y2)\n",
    "            loss.append(temp_loss)\n",
    "        avg_loss = sum(loss)/len(loss) #avg loss on batches\n",
    "        gan_loss = min(gan_loss, avg_loss)\n",
    "        print('----loss=', avg_loss)\n",
    "        # if gan_loss < 1:\n",
    "        #   return gan_loss\n",
    "    print('minimum gan_Loss=', gan_loss)\n",
    "    return gan_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "522zTI4LLzxZ",
    "outputId": "0784d19b-afa2-4435-dc78-c2690ecbdff3"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "#Deep Convolutional GAN\n",
    "# codings_size = [2, 5, 10, 20, 25, 40, 50, 100, 150, 200]\n",
    "codings_size = [100]\n",
    "n_epochs=600\n",
    "gan_loss = []\n",
    "for i in range(len(codings_size)):\n",
    "  print('\\nCODINGS SIZE =', codings_size[i])\n",
    "  generator = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Dense(14 * 14 * 256, input_shape=[codings_size[i]]),\n",
    "      tf.keras.layers.Reshape([14, 14, 256]),\n",
    "      tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.Conv2DTranspose(128, kernel_size=5, strides=2, padding=\"SAME\",\n",
    "                                  activation=\"selu\"),\n",
    "      tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.Conv2DTranspose(128, kernel_size=5, strides=2, padding=\"SAME\",\n",
    "                                  activation=\"selu\"),\n",
    "      tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.Conv2DTranspose(64, kernel_size=5, strides=2, padding=\"SAME\",\n",
    "                                  activation=\"selu\"),\n",
    "      tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.Conv2DTranspose(3, kernel_size=5, strides=2, padding=\"SAME\",\n",
    "                                  activation=\"tanh\"),\n",
    "      # keras.layers.Dense(n_H*n_W*n_C, activation=\"sigmoid\"),\n",
    "      # keras.layers.Reshape([n_H, n_W, n_C])\n",
    "      # keras.layers.Conv2DTranspose(3, kernel_size=3, strides=2, padding=\"SAME\", activation=\"sigmoid\"),\n",
    "      tf.keras.layers.Reshape([n_H, n_W, n_C])\n",
    "  ])\n",
    "  discriminator = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Conv2D(64, kernel_size=3, strides=2, padding=\"SAME\",\n",
    "                          activation=tf.keras.layers.LeakyReLU(0.2),\n",
    "                          input_shape=[n_H, n_W, n_C]),\n",
    "      tf.keras.layers.Dropout(0.4),\n",
    "      tf.keras.layers.Conv2D(128, kernel_size=3, strides=2, padding=\"SAME\",\n",
    "                          activation=tf.keras.layers.LeakyReLU(0.2)),\n",
    "      tf.keras.layers.Dropout(0.4),\n",
    "      tf.keras.layers.Conv2D(128, kernel_size=3, strides=2, padding=\"SAME\",\n",
    "                          activation=tf.keras.layers.LeakyReLU(0.2)),\n",
    "      tf.keras.layers.Dropout(0.4),\n",
    "      tf.keras.layers.Conv2D(256, kernel_size=3, strides=2, padding=\"SAME\",\n",
    "                          activation=tf.keras.layers.LeakyReLU(0.2)),\n",
    "      tf.keras.layers.Dropout(0.4),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(1, activation=\"sigmoid\") #ONE NEURON TO CLASSIFY IT IS REAL OR FAKE\n",
    "  ])\n",
    "  gan = tf.keras.models.Sequential([generator, discriminator])\n",
    "\n",
    "  discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
    "  discriminator.trainable = False\n",
    "  gan.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
    "\n",
    "  # print(X_train.shape)\n",
    "  # X_train_dcgan = X_train.reshape(-1, n_H, n_W, n_C) * 2. - 1. # reshape and rescale\n",
    "  X_train_dcgan = X_train\n",
    "\n",
    "  batch_size = 32 #32\n",
    "  dataset = tf.data.Dataset.from_tensor_slices(X_train_dcgan)\n",
    "  dataset = dataset.shuffle(1000)\n",
    "  dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)\n",
    "\n",
    "  loss = train_gan(gan, dataset, batch_size, codings_size[i], n_epochs)\n",
    "  gan_loss.append(loss)\n",
    "print(\"CODING SIZE =\", codings_size)\n",
    "print('GAN LOSS =', gan_loss)\n",
    "print('minimum gan loss =', min(gan_loss), 'codings size=', codings_size[gan_loss.index(min(gan_loss))])\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 900
    },
    "id": "Yi44hX1cL5oB",
    "outputId": "01a1172a-3ff2-41d2-daee-6bf775967417"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "codings_size = 100\n",
    "noise = tf.random.normal(shape=[batch_size, codings_size])\n",
    "generated_images = generator(noise)\n",
    "plot_multiple_images(generated_images, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2Rj7YOV4L6Uh",
    "outputId": "94dd0e3b-3923-466b-a3e5-98463dc7e8d1"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(8):   #len(images.shape[0])\n",
    "    ax = plt.subplot(4, 2, i + 1 )\n",
    "    plt.imshow(generated_images[i]) #.numpy().astype(\"uint8\"))\n",
    "    # plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WsH7YsreMBQX"
   },
   "source": [
    "# Generate and save the new images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ltRuTt3SL8XA",
    "outputId": "8e6d3990-dc60-41d7-f66e-9a4ceda27b55"
   },
   "outputs": [],
   "source": [
    "bs = 200\n",
    "for j in range(10):\n",
    "  tf.random.set_seed(42)\n",
    "  np.random.seed(42)\n",
    "  noise = tf.random.normal(shape=[bs, codings_size])\n",
    "  generated_images = generator(noise)\n",
    "  plt.figure(figsize=(10, 10))\n",
    "  for i in range(bs):\n",
    "      plt.imshow(generated_images[i]) #.numpy().astype(\"uint8\"))\n",
    "      # plt.title(class_names[labels[i]])\n",
    "      plt.axis(\"off\")\n",
    "      plt.savefig('/content/gdrive/MyDrive/Colab Notebooks/generated1kEpochs/defective/generated_image'+str(j)+str(i)+'.jpg')\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Olk8t69KFiay"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HTixVYMBFiea"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tnBwLsuZhFG4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FoAvACp2MURI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
